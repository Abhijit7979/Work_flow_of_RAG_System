{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "01a40703",
   "metadata": {},
   "source": [
    "#### Prompt templates\n",
    "\n",
    "prompt  templates help to turn raw user information into a format that the llm can work with. In the case, the raw user input is just a message, which we are passing to the llm. let's now make that a bit more complicated. First, let's add in a system message with some custom instructions(but still taking messages as input). Next, we'll add in more input besides just the messages.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "38cdd738",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from rich import print\n",
    "from dotenv import load_dotenv \n",
    "load_dotenv(dotenv_path=\"../.env\")\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")\n",
    "llm=ChatGroq(model=\"gemma2-9b-it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "d8afe227",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "from langchain_core.messages import HumanMessage\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",(\"You are helpful assistant.Answer all the questions to the best of your ability.\")),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain=prompt|llm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "736fb34d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ChatPromptTemplate(input_variables=['messages'], input_types={'messages': list[typing.Annotated[typing.Union[typing.Annotated[langchain_core.messages.ai.AIMessage, Tag(tag='ai')], typing.Annotated[langchain_core.messages.human.HumanMessage, Tag(tag='human')], typing.Annotated[langchain_core.messages.chat.ChatMessage, Tag(tag='chat')], typing.Annotated[langchain_core.messages.system.SystemMessage, Tag(tag='system')], typing.Annotated[langchain_core.messages.function.FunctionMessage, Tag(tag='function')], typing.Annotated[langchain_core.messages.tool.ToolMessage, Tag(tag='tool')], typing.Annotated[langchain_core.messages.ai.AIMessageChunk, Tag(tag='AIMessageChunk')], typing.Annotated[langchain_core.messages.human.HumanMessageChunk, Tag(tag='HumanMessageChunk')], typing.Annotated[langchain_core.messages.chat.ChatMessageChunk, Tag(tag='ChatMessageChunk')], typing.Annotated[langchain_core.messages.system.SystemMessageChunk, Tag(tag='SystemMessageChunk')], typing.Annotated[langchain_core.messages.function.FunctionMessageChunk, Tag(tag='FunctionMessageChunk')], typing.Annotated[langchain_core.messages.tool.ToolMessageChunk, Tag(tag='ToolMessageChunk')]], FieldInfo(annotation=NoneType, required=True, discriminator=Discriminator(discriminator=<function _get_type at 0x1250a81f0>, custom_error_type=None, custom_error_message=None, custom_error_context=None))]]}, partial_variables={}, messages=[SystemMessagePromptTemplate(prompt=PromptTemplate(input_variables=[], input_types={}, partial_variables={}, template='You are helpful assistant.Answer all the questions to the best of your ability.'), additional_kwargs={}), MessagesPlaceholder(variable_name='messages')])\n",
       "| ChatGroq(client=<groq.resources.chat.completions.Completions object at 0x12560e860>, async_client=<groq.resources.chat.completions.AsyncCompletions object at 0x125648d00>, model_name='gemma2-9b-it', model_kwargs={}, groq_api_key=SecretStr('**********'))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "chain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "906dd0f7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">Let me explain Agentic AI. \n",
       "\n",
       "**Agentic AI** refers to artificial intelligence systems that exhibit **autonomous decision-making and \n",
       "goal-oriented behavior**.  \n",
       "\n",
       "Think of an agent like a little program with its own goals and the ability to act in the world to achieve them. \n",
       "\n",
       "Here's a breakdown of key characteristics:\n",
       "\n",
       "* **Goal-Oriented:**  Agentic AI systems are designed with specific objectives in mind. They work towards \n",
       "accomplishing these goals, even adapting their strategies as needed.\n",
       "* **Autonomous:**  They can make independent decisions and take actions without constant human intervention. They \n",
       "learn from their environment and experiences to improve their performance.\n",
       "* **Reactive:** Agentic AI responds to changes in its surroundings. If something unexpected happens, it can adjust \n",
       "its plans accordingly.\n",
       "\n",
       "**Examples of Agentic AI:**\n",
       "\n",
       "* **Self-driving cars:**  They navigate roads, make decisions about speed and lane changes, and avoid obstacles, \n",
       "all while aiming to reach their destination safely.\n",
       "* **Chatbots:**  Advanced chatbots can hold natural conversations, understand user requests, and provide helpful \n",
       "responses.\n",
       "* **Game AI:**  Non-player characters <span style=\"font-weight: bold\">(</span>NPCs<span style=\"font-weight: bold\">)</span> in video games often exhibit agentic behavior, making decisions about \n",
       "their actions based on the game's rules and their goals.\n",
       "\n",
       "**Important Considerations:**\n",
       "\n",
       "* **Ethics:**  As agentic AI becomes more powerful, it's crucial to consider the ethical implications of their \n",
       "actions. Who is responsible when an AI makes a mistake? How do we ensure they act in a safe and beneficial way?\n",
       "* **Safety:**  Designing reliable and safe agentic AI is essential.  We need to prevent unintended consequences and\n",
       "ensure they don't pose risks to humans or the environment.\n",
       "\n",
       "\n",
       "Let me know if you have any other questions about Agentic AI.\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "Let me explain Agentic AI. \n",
       "\n",
       "**Agentic AI** refers to artificial intelligence systems that exhibit **autonomous decision-making and \n",
       "goal-oriented behavior**.  \n",
       "\n",
       "Think of an agent like a little program with its own goals and the ability to act in the world to achieve them. \n",
       "\n",
       "Here's a breakdown of key characteristics:\n",
       "\n",
       "* **Goal-Oriented:**  Agentic AI systems are designed with specific objectives in mind. They work towards \n",
       "accomplishing these goals, even adapting their strategies as needed.\n",
       "* **Autonomous:**  They can make independent decisions and take actions without constant human intervention. They \n",
       "learn from their environment and experiences to improve their performance.\n",
       "* **Reactive:** Agentic AI responds to changes in its surroundings. If something unexpected happens, it can adjust \n",
       "its plans accordingly.\n",
       "\n",
       "**Examples of Agentic AI:**\n",
       "\n",
       "* **Self-driving cars:**  They navigate roads, make decisions about speed and lane changes, and avoid obstacles, \n",
       "all while aiming to reach their destination safely.\n",
       "* **Chatbots:**  Advanced chatbots can hold natural conversations, understand user requests, and provide helpful \n",
       "responses.\n",
       "* **Game AI:**  Non-player characters \u001b[1m(\u001b[0mNPCs\u001b[1m)\u001b[0m in video games often exhibit agentic behavior, making decisions about \n",
       "their actions based on the game's rules and their goals.\n",
       "\n",
       "**Important Considerations:**\n",
       "\n",
       "* **Ethics:**  As agentic AI becomes more powerful, it's crucial to consider the ethical implications of their \n",
       "actions. Who is responsible when an AI makes a mistake? How do we ensure they act in a safe and beneficial way?\n",
       "* **Safety:**  Designing reliable and safe agentic AI is essential.  We need to prevent unintended consequences and\n",
       "ensure they don't pose risks to humans or the environment.\n",
       "\n",
       "\n",
       "Let me know if you have any other questions about Agentic AI.\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(chain.invoke({\"messages\":[HumanMessage(content=\"what is Agentic ai ?\")]}).content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "a573016e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_community.chat_message_histories import ChatMessageHistory\n",
    "from langchain_core.chat_history import BaseChatMessageHistory\n",
    "from langchain_core.runnables.history import RunnableWithMessageHistory\n",
    "\n",
    "\n",
    "store={}\n",
    "\n",
    "def get_session_history(session_id:str)->BaseChatMessageHistory:\n",
    "    if session_id not in store:\n",
    "        store[session_id]=ChatMessageHistory()\n",
    "    return store[session_id]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "69e90b18",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(chain,get_session_history) ## added chain "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "9d70b65d",
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat1\"}}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "1a4fb44b",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=with_message_history.invoke(\n",
    "    [HumanMessage(content=\"hi my name is abhijit\")],\n",
    "                                      config=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f6bb0423",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AIMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"Hi Abhijit, it's nice to meet you! \\n\\nI'm happy to answer any questions you have. Just ask away! 😊  </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">\\n\\n\"</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response_metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'token_usage'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">35</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'prompt_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'total_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">67</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'completion_time'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.063636364</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'prompt_time'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.0014751</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'queue_time'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.24945953</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'total_time'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.065111464</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'model_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gemma2-9b-it'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'system_fingerprint'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'fp_10c08bf97d'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'service_tier'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'on_demand'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'finish_reason'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'logprobs'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'run--f5aeec8a-08d4-4604-b188-235694a6f603-0'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">usage_metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'input_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">32</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'output_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">35</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'total_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">67</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mAIMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mcontent\u001b[0m=\u001b[32m\"Hi\u001b[0m\u001b[32m Abhijit, it's nice to meet you! \\n\\nI'm happy to answer any questions you have. Just ask away! 😊  \u001b[0m\n",
       "\u001b[32m\\n\\n\"\u001b[0m,\n",
       "    \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[33mresponse_metadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "        \u001b[32m'token_usage'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'completion_tokens'\u001b[0m: \u001b[1;36m35\u001b[0m,\n",
       "            \u001b[32m'prompt_tokens'\u001b[0m: \u001b[1;36m32\u001b[0m,\n",
       "            \u001b[32m'total_tokens'\u001b[0m: \u001b[1;36m67\u001b[0m,\n",
       "            \u001b[32m'completion_time'\u001b[0m: \u001b[1;36m0.063636364\u001b[0m,\n",
       "            \u001b[32m'prompt_time'\u001b[0m: \u001b[1;36m0.0014751\u001b[0m,\n",
       "            \u001b[32m'queue_time'\u001b[0m: \u001b[1;36m0.24945953\u001b[0m,\n",
       "            \u001b[32m'total_time'\u001b[0m: \u001b[1;36m0.065111464\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'model_name'\u001b[0m: \u001b[32m'gemma2-9b-it'\u001b[0m,\n",
       "        \u001b[32m'system_fingerprint'\u001b[0m: \u001b[32m'fp_10c08bf97d'\u001b[0m,\n",
       "        \u001b[32m'service_tier'\u001b[0m: \u001b[32m'on_demand'\u001b[0m,\n",
       "        \u001b[32m'finish_reason'\u001b[0m: \u001b[32m'stop'\u001b[0m,\n",
       "        \u001b[32m'logprobs'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'run--f5aeec8a-08d4-4604-b188-235694a6f603-0'\u001b[0m,\n",
       "    \u001b[33musage_metadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'input_tokens'\u001b[0m: \u001b[1;36m32\u001b[0m, \u001b[32m'output_tokens'\u001b[0m: \u001b[1;36m35\u001b[0m, \u001b[32m'total_tokens'\u001b[0m: \u001b[1;36m67\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c997830f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# updating propmt\n",
    "\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",(\"You are helpful assistant.Answer all the questions to the best of your ability in {language}\")),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")\n",
    "\n",
    "chain=prompt | llm\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a6a2a818",
   "metadata": {},
   "outputs": [],
   "source": [
    "response=chain.invoke({\"messages\":[HumanMessage(content=\"hi my name is krish \")],\"language\":\"telugu\"})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "5b323d07",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">మీకు నమస్కారం కృష్ణ! 😊 \n",
       "\n",
       "నేను మీకు సహాయకరమైన సహచరునిగా ఉన్నాను. ఏ ప్రశ్నైనా అడిగండి, నేను నా జ్ఞానానికి అనుగుణంగా మీకు సమాధానం ఇస్తాను.  \n",
       "\n",
       "\n",
       "</pre>\n"
      ],
      "text/plain": [
       "మీకు నమస్కారం కృష్ణ! 😊 \n",
       "\n",
       "నేను మీకు సహాయకరమైన సహచరునిగా ఉన్నాను. ఏ ప్రశ్నైనా అడిగండి, నేను నా జ్ఞానానికి అనుగుణంగా మీకు సమాధానం ఇస్తాను.  \n",
       "\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(response.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e9f898c",
   "metadata": {},
   "source": [
    "Let's now wrap this more complicated chain in a message history class. this time , because there are multiple keys in the input, we need to specify the correct key to use to save the chat history."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "f0b6bee9",
   "metadata": {},
   "outputs": [],
   "source": [
    "with_message_history=RunnableWithMessageHistory(chain,get_session_history,input_messages_key=\"messages\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0e52289f",
   "metadata": {},
   "outputs": [],
   "source": [
    "config={\"configurable\":{\"session_id\":\"chat4\"}}\n",
    "\n",
    "response=with_message_history.invoke(\n",
    "    {'messages':[HumanMessage(content=\"hi, my name is abhijit and i am ai engineer\")],\"language\":\"telugu\"},\n",
    "    config=config\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "1b41ee9d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AIMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'నేను మీకు సహాయకరి అని కూడా చెప్పవచ్చు. మీ పేరు Abhijit అని తెలుసుకున్నాను, అలాగే మీరు AI ఇంజనీర్ అని కూడా తెలుసుకున్నాను.\\n\\nమీరు ఏమి అడిగితే అది</span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">తెలుగులోనే సమాధానం ఇస్తానని గుర్తుంచుకోండి. 😊\\n\\nప్రశ్నలు అడిగి మాట్లాడుకోండి! 🤝\\n\\n'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response_metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'token_usage'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">123</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'prompt_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">40</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'total_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">163</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'completion_time'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.223636364</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'prompt_time'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.00155246</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'queue_time'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.24962632</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'total_time'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.225188824</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'model_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gemma2-9b-it'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'system_fingerprint'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'fp_10c08bf97d'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'service_tier'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'on_demand'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'finish_reason'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'logprobs'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'run--5afda680-1998-4820-b344-495e3371502c-0'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">usage_metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'input_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">40</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'output_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">123</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'total_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">163</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mAIMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mcontent\u001b[0m=\u001b[32m'నేను మీకు సహాయకరి అని కూడా చెప్పవచ్చు. మీ పేరు Abhijit అని తెలుసుకున్నాను, అలాగే మీరు AI ఇంజనీర్ అని కూడా తెలుసుకున్నాను.\\n\\nమీరు ఏమి అడిగితే అది\u001b[0m\n",
       "\u001b[32mతెలుగులోనే సమాధానం ఇస్తానని గుర్తుంచుకోండి. 😊\\n\\nప్రశ్నలు అడిగి మాట్లాడుకోండి! 🤝\\n\\n'\u001b[0m,\n",
       "    \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[33mresponse_metadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "        \u001b[32m'token_usage'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'completion_tokens'\u001b[0m: \u001b[1;36m123\u001b[0m,\n",
       "            \u001b[32m'prompt_tokens'\u001b[0m: \u001b[1;36m40\u001b[0m,\n",
       "            \u001b[32m'total_tokens'\u001b[0m: \u001b[1;36m163\u001b[0m,\n",
       "            \u001b[32m'completion_time'\u001b[0m: \u001b[1;36m0.223636364\u001b[0m,\n",
       "            \u001b[32m'prompt_time'\u001b[0m: \u001b[1;36m0.00155246\u001b[0m,\n",
       "            \u001b[32m'queue_time'\u001b[0m: \u001b[1;36m0.24962632\u001b[0m,\n",
       "            \u001b[32m'total_time'\u001b[0m: \u001b[1;36m0.225188824\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'model_name'\u001b[0m: \u001b[32m'gemma2-9b-it'\u001b[0m,\n",
       "        \u001b[32m'system_fingerprint'\u001b[0m: \u001b[32m'fp_10c08bf97d'\u001b[0m,\n",
       "        \u001b[32m'service_tier'\u001b[0m: \u001b[32m'on_demand'\u001b[0m,\n",
       "        \u001b[32m'finish_reason'\u001b[0m: \u001b[32m'stop'\u001b[0m,\n",
       "        \u001b[32m'logprobs'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'run--5afda680-1998-4820-b344-495e3371502c-0'\u001b[0m,\n",
       "    \u001b[33musage_metadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'input_tokens'\u001b[0m: \u001b[1;36m40\u001b[0m, \u001b[32m'output_tokens'\u001b[0m: \u001b[1;36m123\u001b[0m, \u001b[32m'total_tokens'\u001b[0m: \u001b[1;36m163\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(response)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5ae76162",
   "metadata": {},
   "outputs": [],
   "source": [
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
