{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64f1f65d",
   "metadata": {},
   "source": [
    "#### <b>Managing the conversation History </b>\n",
    "\n",
    "one important concept to understand when building chatbots is how to manage conversation history.if left unmanaged, the list of messages will grow unbounded and potentially overflow the context window of the llm. therefore, it is important to add a step that limits the size of the messages you are passing in.\n",
    "\n",
    "- <b>trim_messages</b> : helper to reduce how many messages we're sending to the model. the trimmer allows us to specify how many tokens we want to keep, along with other parameters like if we want to always keep the system message and whether to allow partial messages."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "35a45f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from dotenv import load_dotenv \n",
    "from rich import print \n",
    "load_dotenv(dotenv_path=\"../.env\")\n",
    "\n",
    "from langchain_groq import ChatGroq \n",
    "\n",
    "\n",
    "os.environ[\"GROQ_API_KEY\"]=os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "llm=ChatGroq(model=\"gemma2-9b-it\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "86f7f2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage,trim_messages,HumanMessage,AIMessage\n",
    "trimmer=trim_messages(\n",
    "    max_tokens=45,\n",
    "    strategy=\"last\",\n",
    "    token_counter=llm,\n",
    "    include_system=True,\n",
    "    allow_partial=False,\n",
    "    start_on=\"human\"\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "4a920986",
   "metadata": {},
   "outputs": [],
   "source": [
    "messages=[\n",
    "    SystemMessage(content=\"you're a good assistant\"),\n",
    "    HumanMessage(content=\"hi! i am abhijit\"),\n",
    "    AIMessage(content=\"hi\"),\n",
    "    HumanMessage(content=\"i like vanilla ice cream\"),\n",
    "    AIMessage(content=\"nice\"),\n",
    "    HumanMessage(content=\"what is 2+2\"),\n",
    "    AIMessage(content=\"4\"),\n",
    "    HumanMessage(content=\"thanks\"),\n",
    "    AIMessage(content=\"no problem!\"),\n",
    "     HumanMessage(content=\" having fun ?\"),\n",
    "    AIMessage(content=\"yes!\"),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d2122b93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[SystemMessage(content=\"you're a good assistant\", additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='what is 2+2', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='4', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content='thanks', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='no problem!', additional_kwargs={}, response_metadata={}),\n",
       " HumanMessage(content=' having fun ?', additional_kwargs={}, response_metadata={}),\n",
       " AIMessage(content='yes!', additional_kwargs={}, response_metadata={})]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trimmer.invoke(messages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "eba03ce3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.prompts import ChatPromptTemplate,MessagesPlaceholder\n",
    "prompt=ChatPromptTemplate.from_messages(\n",
    "    [\n",
    "        (\"system\",(\"You are helpful assistant.Answer all the questions to the best of your ability in {language}\")),\n",
    "        MessagesPlaceholder(variable_name=\"messages\")\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "743fdf36",
   "metadata": {},
   "outputs": [],
   "source": [
    "from operator import itemgetter \n",
    "\n",
    "from langchain_core.runnables import RunnablePassthrough \n",
    "\n",
    "chain=(\n",
    "        RunnablePassthrough.assign(messages=itemgetter(\"messages\")|trimmer)\n",
    "        |prompt\n",
    "        |llm\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f84a9274",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"color: #800080; text-decoration-color: #800080; font-weight: bold\">AIMessage</span><span style=\"font-weight: bold\">(</span>\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">content</span>=<span style=\"color: #008000; text-decoration-color: #008000\">\"As an AI, I don't have access to your personal information, including your ice cream </span>\n",
       "<span style=\"color: #008000; text-decoration-color: #008000\">preferences!\\n\\nWhat's your favorite flavor? ðŸ˜Š  \\n\"</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">additional_kwargs</span>=<span style=\"font-weight: bold\">{}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">response_metadata</span>=<span style=\"font-weight: bold\">{</span>\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'token_usage'</span>: <span style=\"font-weight: bold\">{</span>\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'completion_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">34</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'prompt_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">85</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'total_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">119</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'completion_time'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.061818182</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'prompt_time'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.002573999</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'queue_time'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.246618011</span>,\n",
       "            <span style=\"color: #008000; text-decoration-color: #008000\">'total_time'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">0.064392181</span>\n",
       "        <span style=\"font-weight: bold\">}</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'model_name'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'gemma2-9b-it'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'system_fingerprint'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'fp_10c08bf97d'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'service_tier'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'on_demand'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'finish_reason'</span>: <span style=\"color: #008000; text-decoration-color: #008000\">'stop'</span>,\n",
       "        <span style=\"color: #008000; text-decoration-color: #008000\">'logprobs'</span>: <span style=\"color: #800080; text-decoration-color: #800080; font-style: italic\">None</span>\n",
       "    <span style=\"font-weight: bold\">}</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">id</span>=<span style=\"color: #008000; text-decoration-color: #008000\">'run--cb013430-7fc1-4fa2-82a4-d849b8d0da4d-0'</span>,\n",
       "    <span style=\"color: #808000; text-decoration-color: #808000\">usage_metadata</span>=<span style=\"font-weight: bold\">{</span><span style=\"color: #008000; text-decoration-color: #008000\">'input_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">85</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'output_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">34</span>, <span style=\"color: #008000; text-decoration-color: #008000\">'total_tokens'</span>: <span style=\"color: #008080; text-decoration-color: #008080; font-weight: bold\">119</span><span style=\"font-weight: bold\">}</span>\n",
       "<span style=\"font-weight: bold\">)</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1;35mAIMessage\u001b[0m\u001b[1m(\u001b[0m\n",
       "    \u001b[33mcontent\u001b[0m=\u001b[32m\"As\u001b[0m\u001b[32m an AI, I don't have access to your personal information, including your ice cream \u001b[0m\n",
       "\u001b[32mpreferences!\\n\\nWhat's your favorite flavor? ðŸ˜Š  \\n\"\u001b[0m,\n",
       "    \u001b[33madditional_kwargs\u001b[0m=\u001b[1m{\u001b[0m\u001b[1m}\u001b[0m,\n",
       "    \u001b[33mresponse_metadata\u001b[0m=\u001b[1m{\u001b[0m\n",
       "        \u001b[32m'token_usage'\u001b[0m: \u001b[1m{\u001b[0m\n",
       "            \u001b[32m'completion_tokens'\u001b[0m: \u001b[1;36m34\u001b[0m,\n",
       "            \u001b[32m'prompt_tokens'\u001b[0m: \u001b[1;36m85\u001b[0m,\n",
       "            \u001b[32m'total_tokens'\u001b[0m: \u001b[1;36m119\u001b[0m,\n",
       "            \u001b[32m'completion_time'\u001b[0m: \u001b[1;36m0.061818182\u001b[0m,\n",
       "            \u001b[32m'prompt_time'\u001b[0m: \u001b[1;36m0.002573999\u001b[0m,\n",
       "            \u001b[32m'queue_time'\u001b[0m: \u001b[1;36m0.246618011\u001b[0m,\n",
       "            \u001b[32m'total_time'\u001b[0m: \u001b[1;36m0.064392181\u001b[0m\n",
       "        \u001b[1m}\u001b[0m,\n",
       "        \u001b[32m'model_name'\u001b[0m: \u001b[32m'gemma2-9b-it'\u001b[0m,\n",
       "        \u001b[32m'system_fingerprint'\u001b[0m: \u001b[32m'fp_10c08bf97d'\u001b[0m,\n",
       "        \u001b[32m'service_tier'\u001b[0m: \u001b[32m'on_demand'\u001b[0m,\n",
       "        \u001b[32m'finish_reason'\u001b[0m: \u001b[32m'stop'\u001b[0m,\n",
       "        \u001b[32m'logprobs'\u001b[0m: \u001b[3;35mNone\u001b[0m\n",
       "    \u001b[1m}\u001b[0m,\n",
       "    \u001b[33mid\u001b[0m=\u001b[32m'run--cb013430-7fc1-4fa2-82a4-d849b8d0da4d-0'\u001b[0m,\n",
       "    \u001b[33musage_metadata\u001b[0m=\u001b[1m{\u001b[0m\u001b[32m'input_tokens'\u001b[0m: \u001b[1;36m85\u001b[0m, \u001b[32m'output_tokens'\u001b[0m: \u001b[1;36m34\u001b[0m, \u001b[32m'total_tokens'\u001b[0m: \u001b[1;36m119\u001b[0m\u001b[1m}\u001b[0m\n",
       "\u001b[1m)\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "print(chain.invoke(\n",
    "    {\n",
    "    \"messages\":messages+[HumanMessage(content=\"What ice cream do i like\")],\n",
    "    \"language\":\"english\"\n",
    "    }\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53b0c292",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
